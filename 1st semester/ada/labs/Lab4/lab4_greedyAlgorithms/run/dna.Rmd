---
title: "Analysis of Greedy DNA Reconstruction Algorithms"
author: "Jose Torres Postigo"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    fig_caption: yes
    toc: false
    extra_dependencies: ["placeins", "subfig"]
papersize: a4
fontsize: 11pt
geometry:
  - top=1in
  - bottom=1in
  - left=1in
  - right=1in
params:
  filename_naive: "NaiveGreedyPathSequencing-stats.txt"
  filename_bidirectional: "NaiveBidirectionalGreedyPathSequencing-stats.txt"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

# Objectives

The objectives of this lab excercise is the implementation, evaluation and comparison of the performance of two DNA sequencing algorithm implementations: the NaiveGreedyPathSequencing and NaiveBidirectionalGreedyPathSequencing. 

Both algorithms aim to reconstruct a DNA sequence from a set of fragmented reads obtained through Shotgun sequencing. The unidirectional naive algorithm follows a simple greedy approach, selecting the next fragment based on maximum overlap. The bidirectional variation extends the NaiveGreedyPathSequencing by considering extensions in both forward and backward directions.

Finding the best reconstruction is equivalent to finding the minimum Hamiltonian path (path that visits each vertex exactly once), if we imagine a weighted complete directed graph $G(V,\ E, \ w)$, where

- There is a vertex $v_i$ for each fragment $f_i,\ 1 \le n$.

- There is a directed edge $(v_i,\ v_j)$ for $1 \le\ i,\ j \le n$.

- The weight $w((v_i,\ v_j))$ of each edge is the overlap $\omega(f_i,\ f_j)$.

A generic greedy path-building approach for the Hamiltonian path problem would pick a starting vertex and then subsequently select the next vertex to visit in a greedy way.

Adapting this aproach for the DNA assembly problem, in the unidirectional implementation we pick an intial fragment at random and then in each step we assemble the fragment (among those still available) with the largest overlap to the last one picked. For the improved version of this, the bidirectional variation, it will be picked a fragment to be assembled to either of the two end, whatever it is better.

# Experimental Setup

For these experiments, both algorithms will be run through a class given by the lecturer, which is going to run tests for them using sequences and reads of incresing number. The initial values for these tests are 
five sequence lengths, starting at a size of 128 and doubling each time, with read sizes from 4 to 8 and 100 tests per parameter combination; up to sequences with a size of 2048.  
```{=tex}
\begin{table}[!h]
\caption{Computational environment considered.}
\begin{tabular}{lp{0.8\linewidth}}
\hline
CPU       & Intel® Core™ i5 11600KF, 16GB \\
OS        & Windows 11 Home 22H2 \\
Java      & openjdk 17.0.7 2023-04-18 \\
\hline
\end{tabular}
\label{tab:conf}
\end{table}
```
# Empirical Results

A summary of the experimental results is provided in Tables \@ref(tab:data-summary-naive) and \@ref(tab:data-summary-bidirectional) in the Appendix.

In Figure 1, it can be seen the plots regarding the time as a function of the sequence length for different reads lengths. Taking a look at the results, it can firmly be said that, although for small sequences both take approximately the same time, in general the naive implementation is very fast, while the bidirectional implementation is much slower. 

This is because the naive implementation simply reads the DNA sequence from one end to the other, while the bidirectional implementation reads the sequence from both ends simultaneously. This makes the bidirectional implementation slower, but the length excess is going to be lower, because it is less likely to miss a better read.

For both implementations, the time complexity seems to be $O(n\ log\ n)$. Studying the plots, the time complexity do not depend on the length of the fragments because they present the same growth rate for different read lengths. The sequence length of the input, however, is a key factor that affect directly to the time complexity.

In Figure 2, it can be seen the plots regarding the length excess of the reconstructed solution as a function of the sequence length for different read lengths. The first plot shows the results for the naive implementation of the algorithm, and the second plot shows the results for the bidirectional implementation.

The naive implementation of the algorithm is very fast, as has been pointed out above, but presents a larger percentage of length excess than the bidirectional implementation. This is because the naive implementation simply reads the DNA sequence from one end, missing possible better matches if this occurs at the other end of the sequence.

The bidirectional implementation of the algorithm, although is slower than the naive implementation, it is less likely to miss the best match in each case. This is because the bidirectional implementation reads the DNA sequence from both ends simultaneously. 

It is a surprise that the bidirectional implementation is very inaccurate regarding the theoretical predictions of the length excesses. Some of the readings made in the execution are much lower than the theoretical prediction, others much higher.
```{r load-data}
# makes a power fit from triples (x, y, z), where 
# z is the dependent variable and triples are sorted
# first by x value and then by y value. It is assumed that for 
# each x value there are series_length values of y
makefit <- function (x, y, z, series_length) {
  n <-length(x);
  ind <- seq(2*series_length,n,series_length);
  c0 <- mean(log(z[ind]/z[ind-series_length])/log(x[ind]/x[ind-series_length]))
  b0 <- mean(log(z[ind]/z[ind-1])/log(y[ind]/y[ind-1]))
  a0 <- mean(z[ind]/(y[ind]^b0 * x[ind]^c0))
  datafit = nls(z ~ a * y^b * x^c, 
                data = data.frame("x" = x, "y" = y, "z" = z), 
                start = list(a = a0, b = b0, c = c0))
  columns <- c("x", "y", "predicted", "read_length")
  newdata <- data.frame (matrix(nrow = 0, ncol = length(columns)))
  colnames(newdata) <- columns
  k <- 1
  for (i in seq(x[1], x[n])) {
    for (j in seq(y[1], y[series_length])) {
      newdata[k, "x"] = i
      newdata[k, "y"] = j
      newdata[k, "read_length"] = sprintf("%d", j)
      k <- k + 1
    }
  }
  newdata$predicted <- predict(datafit, newdata)
  list("fit" = datafit, "predicted" = newdata)
} 

read_data <- function(filename) {
  # Reading the data
  rawdata = read.table(filename);
  # Compute basic statistics 
  n <- dim(rawdata)[2];
  one_ind <- seq(3, n, 3)
  two_ind  <- seq(4, n, 3)
  three_ind  <- seq(5, n, 3)
  stderr <- function(x) sd(x)/sqrt(length(x))
  dataframe <- data.frame(
    "seqlength" = rawdata[,1],
    "readlength" = rawdata[,2],
    "read_length" = sprintf("%d", rawdata[,2]),
    "time" = apply(t(rawdata)[one_ind,], 2, mean),
    "timeerr" = apply(t(rawdata)[one_ind,], 2, stderr),
    "sollength" = apply(t(rawdata)[two_ind,], 2, mean),
    "sollengtherr" = apply(t(rawdata)[two_ind,], 2, stderr),
    "diff" = apply(t(rawdata)[three_ind,], 2, mean),
    "differr" = apply(t(rawdata)[three_ind,], 2, stderr)
  )
  
  num_read_values <- length(unique(dataframe$readlength))
  lt <- makefit(dataframe$seqlength, dataframe$readlength, dataframe$time, num_read_values)
  ll <- makefit(dataframe$seqlength, dataframe$readlength, dataframe$sollength-1, num_read_values)
  result <- list("dataframe" = dataframe, "lt" = lt, "ll" = ll)
}

datanaive <- read_data(params$filename_naive)
databidirectional <- read_data(params$filename_bidirectional)

```

```{r time, fig.cap="Time as a function of the sequence length for different read lengths.", fig.subcap=c('naive', 'bidirectional'), fig.asp=1, fig.width=3}
library(ggplot2)
create_figure_time <- function(dataframe, lt, title) {
  figure_time <- ggplot(data=dataframe, aes(x=seqlength, y=time, colour = read_length, group=read_length)) + 
    geom_errorbar(aes(ymin=time-timeerr, ymax=time+timeerr), width=.02) +
    geom_line(data = lt$predicted, aes(x=x, y=predicted)) +
    geom_point(shape=21, size=3, fill="white") +
    xlab ("sequence length") +
    ylab ("time (s)") +
    theme_bw() + 
    theme(legend.justification = c(0, 1), 
          legend.position = c(0, .99), 
          legend.box.margin=margin(c(5,5,5,5)),
          legend.background = element_rect(fill='transparent')) +
    ggtitle(title)
  show(figure_time)
}

create_figure_time(datanaive$dataframe, datanaive$lt, "naive")
create_figure_time(databidirectional$dataframe, databidirectional$lt, "bidirectional")

```

```{r length, fig.cap="Length excess of the reconstructed solution as a function of the sequence length for different read lengths.", fig.subcap=c('naive', 'bidirectional'), fig.asp=1, fig.width=3}
library(ggplot2)

create_figure_length <- function(dataframe, ll, title) {
  figure_length <- ggplot(data=dataframe, aes(x=seqlength, y=100*(sollength-1), colour = read_length, group=read_length)) + 
    geom_errorbar(aes(ymin=100*(sollength-sollengtherr-1), ymax=100*(sollength+sollengtherr-1)), width=.02) +
    geom_line(data = ll$predicted, aes(x=x, y=100*predicted)) +
    geom_point(shape=21, size=3, fill="white") +
    xlab ("sequence length") +
    ylab ("length excess (%)") +
    theme_bw() + 
    theme(legend.justification = c(0, 1), 
          legend.position = c(.5, .99), 
          legend.box.margin=margin(c(5,5,5,5)),
          legend.background = element_rect(fill='transparent')) +
    ggtitle(title)
  show(figure_length)
}

create_figure_length(datanaive$dataframe, datanaive$ll, "naive")
create_figure_length(databidirectional$dataframe, databidirectional$ll, "bidirectional")

```

\FloatBarrier

# Discussion
Comparing the algorithms involves assessing their performance in terms of both time complexity and the length of the reconstructed sequence. The experimental results obtained have been analyzed from running both the unidirectional and bidirectional implementations under different scenarios. 

After studying the results, it can be said that the naive implementation of the DNA sequence algorithm is probably the most commonly used implementation because it is fast enough for most applications. However, the bidirectional implementation is more accurate, especially for longer sequences. So it is up to each one to make the decision of what implementation is going to use, depending on what are their necessities.

In general the theoretical predictions are very accurate, except the one seen in Figure 2 for bidirectional implementation. This could be for some reasons: the Hardware of this experimental setup is not the appropiate one or there is some error in the implementation. It could not be, in my opinion, a problem with the regression model because the readings obtained are kind of random.

\FloatBarrier

```{=tex}
\setcounter{section}{0}
\renewcommand{\thesection}{\Alph{section}}
```
# Appendix

## Data Summary

Summary of the experimental results for sequences and reads of different sizes. The mean and standard error are provided for the computational time and the length excess of the sequence generated over the true solution.

```{r data-summary-naive}
library(knitr)
library(kableExtra)
create_table <- function(dataframe, text) {
  table_dataframe <- data.frame(
    "seq" = dataframe$seqlength,
    "read" = dataframe$readlength,
    "time_mean" = format(dataframe$time, scientific=FALSE, digits = 1),
    "time_err" = format(dataframe$timeerr, scientific=FALSE, digits = 1),
    "excess" = format(100*(dataframe$sollength-1), scientific=FALSE, digits = 2),
    "excesserr" = format(100*dataframe$sollengtherr, scientific=FALSE, digits = 2)
  )
  kable(table_dataframe, 
        longtable = TRUE,
      col.names = c("sequence", "read", "time (mean)", "time (stderr)", "excess (mean)", "excess (stderr)"),  
      caption = text) %>%
  row_spec(0,bold=TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
}

create_table(datanaive$dataframe, "Results for the naive greedy algorithm.") 

```

```{r data-summary-bidirectional}
create_table(databidirectional$dataframe, "Results for the bidirectional greedy algorithm.") 
```

## Model Fitting

Summary of the statistical models found. In all cases, $x$ corresponds to sequence length, and $y$ to read length.

### Naive Greedy Algorithm

#### Model for time

```{r}
show (datanaive$lt$fit)
```

#### Model for length

```{r}
show (datanaive$ll$fit)
```

### Naive Bidirectional Greedy Algorithm

#### Model for time

```{r}
show (databidirectional$lt$fit)
```

#### Model for length

```{r}
show (databidirectional$ll$fit)
```
