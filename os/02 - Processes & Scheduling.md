# 1. Program Concept
## 1.1 Definitions
It is a sequence of instructions that implement an algorithm to solve a problem. Source files are edited and compiled to later link them to each other and static libraries. A program can be started in the terminal with the command: `./program_name`

When creating a process, an OS program loads the program instance into memory, the PC is loaded with the memory location of the first instruction to start execution.

The terms *process*, *task* or *work* will be used synonymously.
## 1.2 Multitasking & Multiprogramming
That many processes share a single processor, memory, and I/O devices creates a concurrency problem. The OS is responsible for solving this task, acting as a multiplexer of the processes. You can make more than one instance of a program by creating a new image of the process that runs independently of the other.

## 1.3 Virtual address spaces
When a program is executed, the memory model we have is the following:

![[Pasted image 20240708003554.png]]

**Code segment (static size, RO access)**
- Contains the machine code generated by the compiler (project files + libraries). 
- It size is fixed.
- It has read-only access (*except with virus infections*).

**Data segment (static size, RW access)**
- This is the memory space reserved by the compiler to store global variables. 
- It’s size if fixed. 
- It has read/write access.

**Heap segment (dynamic size, RW access)**
- This is the space used by the dynamic memory (malloc/free). The size changes depends on the execution of the program. 
- It grows and shrinks dynamically. 
- Read/write access.

**Stack segment (dynamic size, RW access)**
- This is the space for the CPU stack. The size varies with the execution of the program and the type of algorithms. 
- It grows dynamically. 
- It has read/write access.
## 1.4 Why use processes?
- The *simplicity/modularity* (code maintainability), 
- *Performance/efficiency* (multiprogramming/tasking/user) 
- *Security/protection* (errors that only affect the process)

# 2. Representation of Processes
The OS maintains data structures for each process and resource in the system:
- **Processes**: Image information.
- **Memory**: main and secondary memory allocation information; memory map...
- **I/O devices**: information status, availability
- **Files**: states, attributes.

These data structures are cross-referenced, each having a memory reference to the other. These data structures are created during the OS installation; although they can also be created with those that connect hot, without restarting the computer (hot-plug devices).

The **process image** is the text, data and state information (**PCB**, **task_struct in Linux**) of a process at a certain time, its location depends on the memory model:

![[Pasted image 20240708003837.png]]

## 2.1 Process Queue
An image of the process transparent to the user is created through the loader. **Data structures** are **created** to manage the process (on Linux using fork) and **allocate memory** for the image from the executable file (on Linux using exec).

It works as a **queue of process pointers**, whose order can be interrupted by an event. The dispatcher is in charge of changing the process that is executed.

# 3. States of Processes
## 3.1 Three states model
- **Running**: A process in execution (one process per processor)
- **Ready**: Processes waiting to be assigned to a processor (image loaded in memory)
- **Blocked**: Processes waiting for events (I/O completion, communication, signal, ...)

![[Pasted image 20240708004628.png]]

To solve the management of many processes, queues are used. Multiple processes, with priority queue.

In **multiprogramming** systems, they are not removed from execution until the process makes a system call (syscall), while **multitasking** can alternate the state of the process from running to ready if it consumes too much time (**timeout or change by priority**).

## 3.2 Five states model
- **Running**: A process in execution (one process per processor)
- **Ready**: Processes waiting to be assigned to a processor (image loaded in memory)
- **Blocked**: Processes waiting for events (I/O completion, communication, signal, ...)
- **New**: Newly created processes whose admission will depend on the availability of resources or restrictions such as real-time operation.
- **Terminated** (*Zombie* on Linux): while freeing the memory locations that were allocated for structures, etc.
![[Pasted image 20240708004950.png]]


>In **preemptive multiprogramming**, a timer or high-priority process interrupt can stop the execution of a process; In contrast, in **cooperative multiprogramming** the process gives up the CPU voluntarily, in cooperative or battery systems.

## 3.3 Seven states model / with suspended state
It has a suspended state for when the system is overloaded or waiting for an I/O whose speed does not reach that of the CPU, which in turn can be distinguished between **Suspended & Blocked** (S&B); and **Suspended & Ready** (S&R).

The images of these processes will then be moved to secondary storage and returned to either support a new process, activate a process that was suspended but is ready to run; or allocate memory for running processes that require more memory capacity. It is **prioritized** to **suspend** the **blocked** and **reactivate** the **S&R**.

Un proceso **S&B** puede pasar a **S&R** en la finalización de un evento.

![[Pasted image 20240708005538.png]]

## 3.4 Multitasking & Multiprogramming
The advantages of **multitasking** with these models are allowing multi-user systems; resource and CPU usage is maximized; and “facilitates” programming with the cooperation of small programs and modularity.

**Multiprogramming**, meanwhile, has its limits with respect to the number of processes that the system runs. Increasing ready-state processes can increase system response time; In addition, swaps to secondary memory (HDD/SSD) are costly in terms of the time required.

# 4. Operations in processes
## 4.1 Creation
Because a process can create another process, a process tree can be maintained where a parent has one or more child processes. A parent and child process can be executed concurrently, but the parent must wait for the child to finish.

The process image can be **cloned**, making the child a copy (fork) of the parent or **different** (exec).

The operating system must create a new entry in the queue process.

## 4.2 Termination
It consists of the OS eliminating the process through an instruction. Resources assigned to the process are deleted and recovered. A parent can kill its child (process) with a syscall like `kill()`, either by exceeding resource usage, terminating the parent's process, or not being necessary.

The termination of a process can occur by the process itself calling to terminate (the `exit()` syscall), exceeding the process limit, protection (a non-privileged user accessing addresses that it should not), exceptions, death of the parent process ( in Unix it remains like a zombie) or OS interventions (deadlock, two processes have a memory address locked and want to access the memory address of the other).

## 4.3 Dispatching. Context Switch
It is the change of the CPU allocation of a process in multitasking and multiprogramming systems. It can occur when a time interrupt (quantum), device I/O, exception (overflow, page fault...) or system call (int / trap) is raised.

As with how interrupts work:
1. **Hardware**
	1. Saves the PC (Program Counter) and SR (State Register).
	2. Switch to kernel mode.
	3. Loads the address of the interrupt handling routine (IHR) into memory.
		1. The address is obtained from the vector table (IVT).
		2. The IVT is indexed with the vector number.
2. **Software**
	1. The routine saves the state of the process.
	2. The IHR is executed.
	3. The process state is restored.
3. **Hardware**
	1. User mode is restored with PC and SR previously saved.

The process will be similar:
1. By hardware, the state of the current process (PC and SR) is saved; and then, by software, the SP, GPR, PTBR... on the PCB.
2. The IHR is executed.
3. A new process is loaded, the opposite is done in step 1.
4. The new process is executed
5. Step 1 is repeated.

With hardware, the PC and SR are saved by Hardware before it changes due to the interaction of the software with the program counter and is reloaded the other way around, with the same reasoning.

Process management takes away execution time due to context saves and updates, changing memory mapping, reloading selected processes...

To reduce the time in which the context switch acts, hardware improvements were made such as a set of register files and machine code to switch contexts, the saving of pids (process identifier) ​​in virtual caches (TLB); and by design it was improved to avoid full context switches for some system calls that did not require memory mapping changes. The other option is threads.

# 5. Threads
A process can be differentiated by two aspects: Planning and memory allocation. With this we can distinguish between threads and processes:

- The process is the unit with resources allocated beyond the CPU.
- The thread is the unit to be planned; the unit of CPU allocation.

Several threads can leave a process sharing memory mapping, although without the same registers, stack and PC.

Support for threads is provided with **user threads**, which are not in charge of the OS and can be created with user libraries and deleted when there is a system call; and **kernel threads**, with slower creation than user threads, but faster than processes, if one crashes, the kernel can schedule another.

Its advantages are also scalability in multicore architectures (parallel execution), resource sharing that facilitates communication between threads and allows lighter context switches. Its disadvantages occur more at the level of programming and understanding of the program.

# 6. Process & Threads in Linux
Linux maintains a process tree, for process management:

The first process is `systemd` or system/init, this creates the Daemon process `logind`, which in turn creates a bash Shell for user authentication, who will create other processes from the Shell.

A Daemon process is a special OS process that runs in the background (without being tied to the terminal), they are not interactive except for `logind`. They wait for an event or a period of time to execute (`cron`). They are also used on servers in ports.
## 6.1 POSIX Standard
- *Process creation*: `fork()`
- *Executable loading*: `exec()`
- *Process termination*: `exit()`
- *Status collection*: `wait()`
- *Parent/child synchronization*: `fork()/kill()/wait()`
- *Signals*: `signal()`, `kill()`

## 6.2 Threads
POSIX also features an API for threads. Among the functions it provides are:
- `int pthread_create`
- `int pthread_join`
- `int pthread_exit`
- `pthread_t pthread_self`

Unlike processes, there is no hierarchy.
# 7.  Scheduling
Planning (scheduling) are the **policies** and **mechanisms** that decide the order in which processes are executed. The criteria to consider may be performance, efficiency, balance or predictability among others.

The CPU and I/O alternate with **bursts**, if few CPU bursts occur, it is said to be a CPU-bound process; If too many occur, they are considered I/O-bound.

**Priority** can be defined based on concepts internal or external to the OS, as well as implemented statically or dynamically.

Planners can be differentiated into several types:
- **Long term**: decide which to admit into the ready queue.
- **Medium term**: Control memory usage and system load. Virtual memory has replaced that function in modern OSes.
- **Short term**: Responsible for removing elements from the ready process queue. It must be fast and ensure that the context switch is frequently invoked to select the next process to be executed; The component in charge is the dispatcher.

## 7.1 Quantitative criteria
- **CPU usage**, as long as you keep the CPU busier, the better.
- **Throughput**, maximize the processes completed per unit of time.
- **Turnaround time**, from the beginning of the process to its completion. $t_t$
- **Waiting time**, $T_w = t_t - t_{\text{running}} - t_{\text{blocked}}$
- **Response time**
- **CPU usage** is calculated as: $$\frac{T_{\text{user}} + T_\text{system}}{T_{\text{real}}}$$
## 7.2 Scheduling Algorithms
### 7.2.1 Classification
The scheduling algorithm when a process interruption occurs: when it exits, an I/O... is executed; and planning: priority queue of ready processes, bursts...

We found two different ways of implementing planning, either **non-preemptive** (multiprogramming), with the risk of monopolizing the CPI; or **preemptive** (multitasking), although the time of context switches increases.
![[Pasted image 20240708012248.png]]

### 7.2.2 Policies
- **FCFS** (First Come First Served: FIFO)
	- *Non-Preemptive*. The Running process is preempted only when exiting or requesting I/O (multiprogramming)
	- *Scheduling*. Order of arrival (FIFO)
	- *Advantage*: easy to implement
	- *Disadvantages*: waiting times are high.
- **Round Robin** (RR): the program stops executing when it consumes the quantum
	- *Preemptive*. The Running process is preempted when exiting, requesting I/O, or consuming quantum (Q) (multitasking)
	- *Scheduling*. Order of arrival (FIFO)
	-  *Advantage*: Enhances interactivity
	- *Disadvantage*: Increases number of context switches
	- If the multiprogramming degree is $N$, and the quantum is $Q$, the response time is limited by: $t_{response} \leq N \cdot Q$
- **Shortest Job First** (SJF): Shorter processes are prioritized.
	- *Non-Preemptive*. The Running process is preempted only when exiting or requesting I/O (multiprogramming)
	- *Scheduling*. Queue ordered by next CPU-burst time of processes
	- *Advantage*: reduces average times, $t_w$ and $t_t$
	- *Disadvantage*: CPU-bound processes get affected
- **Shortest Remaining Time First** (SRTF)
	- Preemptive. The Running process is preempted when exiting, requesting I/O, or due to a new process with shorter CPU-burst
	- Scheduling. Queue ordered by next CPU-burst time of processes
	- Disadvantages: CPU-bound processes may not terminate (starvation)
	- Solution: Update priority depending on waiting time (aging): HRRN Scheduler
	- Advantages: Minimizes $t_w$ and maximizes throughput (processes/s) in interactive systems

### 7.2.3 Multilevel queues
Process scheduler, general purpose system with processes of various types. Use a different scheduler for each type of processes.

### 7.2.4 Multilevel feedback queues

## 7.3. Solving Exercises
1. Scheduler description
	- Identify schedulers involved in current exercise 
		- Type of scheduler? long/short term 
		- What does it schedule? jobs/processes 
	- Describe scheduler in terms of: 
		- Order of ready queue (FIFO, ordered insertion)
		- Types of preemption (on-exit, start-I/O, quantum, priority)
		- Definition of priority function (constant, dynamic, function of process history…) 
2. Specific processes to be executed in this example
	- Locate information about processes used by this scheduler (total job length, CPU and I/O bursts, quantum, priority).
	- Determine arrival time of processes from problem description (it may be specified for each process or consider that all of them arrive just at time=0). 
3. Manual scheduling of process execution. 
	- Draw a Gantt Chart illustrating scheduling of processes (time is horizontal axis and processes vertical axis). Use at least three styles for lines representing run, ready and blocked states of processes.
	- At the same time, write a history of contents of data structures representing run, ready and blocked states. Draw queue contents at each instant.
4. Evaluate results after ending execution. Each type has different statistics to calculate.